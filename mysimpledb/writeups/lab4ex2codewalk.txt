Lab 4 Code Walk
---------------

Walk thru 1: simpledb.Parser.main() and simpledb.Parser.start()

	simpledb.Parser.main() is the entry point for the SimpleDB system. It calls simpledb.Parser.start(). The latter performs three main actions:
		1) It populates the SimpleDB catalog from the catalog text file provided by the user as argument (Database.getCatalog().loadSchema(argv[0]);).
		2) For each table defined in the system catalog, it computes statistics over the data in the table by calling: TableStats.computeStatistics(), which then does: TableStats s = new TableStats(tableid, IOCOSTPERPAGE);
		3) It processes the statements submitted by the user (processNextStatement(new ByteArrayInputStream(statementBytes));)

Walk thru 2: simpledb.Parser.processNextStatement()

	This method takes in the user input and attempts to parse it as SQL, using
	the Zql parsing library.  This method handles bad user input, as well as valid SQL statements include INSERT, DELETE, and SELECT statements.  

	We focus on the SELECT statement which is handled by 
		handleQueryStatement((ZQuery)s)
	This returns a Query object, which is then executed by calling
		query.execute();

Walk thru 3: simpledb.Parser.handleQueryStatement()

	This method creates a new Query object using the TransactionId passed as a parameter
	and a new LogicalPlan object using the TransactionId and ZQuery object parameters.
	The LogicalPlan object is the logical plan for the parsed query.
	The physicalPlan method is then called on the LogicalPlan object to get a DbIterator
	which is the root of the physical plan.  The physicalPlan method takes a hashMap of the table's stats
	to make its decisionThe Query object's logical plans and physical plan are then set
	using those respective objects.	The method then invokes the QueryPlanVisualizer if the class is available.
	The method returns the Query object it created. 

Walk thru 4: simpledb.Parser.parseQueryLogicalPlan()

	A vector storing ZFromIt objects (which represent the tables used in the Query) is extracted from the ZQuery object using the getFrom method (i.e. we get the tables stated in the From clause).  A new LogicalPlan object, lp, is created.  The lp.setQuery(q.toString()) method is called.  For each element in the vector, we try to get the table id for the specified table from the element.  We get the alias (name) of the table and add a scan (to scan that table) to our Logical Plan.  
	Next, the method deals with the where clause.  We use the getWhere method to get the where clause from the ZQuery object.  We check the where clause for any nested queries, which are not supported.  We then create a new where Zexpression object for the where clause and call the processExpression method on that expression.  The processExpression function first checks the expression for operators (i.e. AND, OR), which are not supported.  We then determine if the op is a join or some other binary operation query.
	If the operation is a join, we parse the two fields and the operator in the join predicate and add the corresponding join to the logical plan.  If the operation is a filter, we parse the column name, the predicate operation, and the value to compare the values in the column to.  We then add the filter to the logical plan.
	Back in parseQueryLogicalPlan(), we now get the group by fields by using the q.getGroupBy().  At most one group by clause is supported.  If there is only 1, we get the group by field and print it out.  Next we check that the select clause is valid (i.e. no expressions) and parse it.  We look for aggregates.  If there are aggregates, we make sure that the aggregates are on at most one field.  We add each field we want to project to the LogicalPlan. We then check to make sure that all non-aggregate fields appear in the group by field, if there are aggregates in the select clause.  We make sure that there is no group by if there are no aggregates, and then add any aggregates to the LogicalPlan.  We check for an order by and if it exists, we add it to the LogicalPlan.
	We then return the LogicalPlan.

	Note: this method is rather long and complex.  Your walk thru should focus
	on the high-level ideas.  Specifically, explain how SQL query is processed to construct the LogicalPlan.  
 
Walk thru 5: simpledb.LogicalPlan.physicalPlan()

	Your walk thru should explain how these data structures are used:
		- equivMap
		- filterSelectivities
		- statsMap
		- subplanMap
	We create an iterator over the tables in a vector (the tables used in the logical plan), a HashMaps equivMap, filterSelectivities, and statsMap.
	For each table in the logical plan:
		We get an iterator to sequentially scan the table, and store that iterator in subplanMap using the table alias as the key.
		We get the TableStats for that table using the baseTableStats.get method, and add the TableStats to the statsMap using the baseTableName as a the key.
		We add the value 1.0 to filterSelectivities using table.alias as the key.
	We then create an iterator over the filters vector (which contains filters in the logical plan).
	For each filter:
		we get the subplan for the table being filtered from subplanMap.  We get the TupleDesc for that table, the field type for the field being filtered, and the predicate used in the filter.  We then put the new filter in our subplan map with the key being the table alias.
		We use the statsMap to get the TableStats, s, for the table being filtered and then use the s.estimateSelectivity method to get an estimate of the selectivity of the filter.  We then store this in filterSelectivities, using the table alias as the key.
	We then create a new JoinOptimizer Object and use the orderJoins() method to create an efficient join on the tables.
	At this point joins is a vector of LogicalJoinNodes, where each node is basically a join of two tables.  For each such node in the vector, we use equivmap to get most accurate table alias for a relation.  Note that when we decide to join to tables, we store the resulting relation under the left table's (table1) alias, and add an entry to equivMap using the right table's alias a key.  Thus, if we try to join or access the rightmost table again, equivMap allows us to access the joined table (table1 join table2) using table2's alias.
	We use the jo.instantiateJoin method to get an iterator for a join, store that iterator in the subplanMap under the left table's alias, and remove the bucket for which right table's alias is a key.  We then look for values in equivMap equal to right table's alias and change those values to be table1's alias.
	We then create two ArrayLists to store the select output fields (the output fields we will project) in the order they will be projected in and types respectively by looking at each select in selectList.  We check for groupby and aggregates and orderbys in those selects, and if they exist we create a new node for each storing the field used the any other settings (i.e. ascending or descending order, the aggOp, etc.).

Walk thru 6: simpledb.JoinOptimizer.orderJoins()

	Use Selinger-style dynamic programming to select the least cost join plan.  Slight modifications to the algorithm result from using join nodes instead of relations.  We conisder all linear plans since we can have a base table as either the outer or the inner relation in the join (vs left-deep where the base table must always be the inner).  We use computeCostAndCardofSubplan to determine the cost of joining a specified join node to the rest of the subplan.  In addition, we use enumerateSubsets to get all subsets of joins of a specified size.  The PlanCache class stores the estimated costs for joins already considered in the dynamic programming algorithm.  Moreover, filterSelectivites and Table stats are used to estimate these costs.

Walk thru 7: JoinOptimizer.computeCostAndCardOfSubplan()

	Takes the subset of joins, a particular join to be joined last, the filterSelectivities, the TableStats, and the best cost so far for the subset, and the PlanCache as parameters and returns a CostCard object which is made up of the cost, size of the resulting relation, and best cost join ordering.  It uses previously best join ordering costs in PlanCache and stats from filter selectivities and Table stats to estimate the best join ordering when joining a particular join last.  To do so it selects the minimum of adding the cost of best join ordering of the subset to the cost of joining with the specified join as either the inner or outer relation

Walk thru 8: JoinOptimizer.estimateJoinCost()

	Takes the size of each table (specified right and left) and the estimated costs of a full scan of each table and returns the estimated cost of the join (which is not only I/Os, but CPU operations as well-- but in our implementation it actually is only I/Os).  Assuming basic nested loops, the cost is cost1 + size1 * cost2 (where table1 is right and table 2 is left).

Walk thru 9: JoinOptimizer.estimateJoinCardinality()

	Estimates the size of the relation that results from the join.  Makes a call to estimateTableJoinCardinality.  For equality operations, this returns the estimate: size1 * size2 /  max ( V(A, t1), V(B, t2)) where we are joining t1 with t2 where t1.A = T2.B and V(attr, table) is the number of distinct values for table.attr in table.  
	For range queries, we return a fixed fraction of the proportional to input size (i.e. 30% of cross product size).  If either attribute is a primary key, we know that the size of the result is less than the size of the other table.

Walk thru 10 query.execute()
	
	Note: This is called inside simpledb.Parser.processNextStatement().  Refer back to Walk thru 2.

	This actually executes the query.  The Query object has an iterator for the physical plan and executes the query by pulling tuples through the pipeline.  It prints out the fieldnames first, and then prints out each tuple that it pulls through the pipeline.

